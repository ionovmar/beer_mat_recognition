{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    show(image, 'Origin image')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    show(gray, 'gray')\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edged = cv2.Canny(gray, 70, 100)\n",
    "    show(edged, 'edged')\n",
    "\n",
    "    # define a (3, 3) structuring element\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "\n",
    "    # apply the dilation operation to the edged image\n",
    "    dilate = cv2.dilate(edged, kernel, iterations=2) # init 1\n",
    "    show(dilate, 'dilate')\n",
    "    return dilate\n",
    "def find_contours(image, dilate):\n",
    "    # contours detection\n",
    "    contours,hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_4_plot = image.copy()\n",
    "    areas = []\n",
    "    for cnt in contours:\n",
    "        # Get the 4 points of the bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w*h>10000:\n",
    "            # Draw a straight rectangle with the points\n",
    "            img_box = cv2.rectangle(image_4_plot, (x, y), (x+w, y+h), color = (255, 0, 0), thickness = 2)\n",
    "            areas.append([x, y, w, h])\n",
    "    show(image_4_plot, 'Contours')\n",
    "    return image_4_plot, contours, areas\n",
    "\n",
    "def crop(image, areas):\n",
    "    mats = []\n",
    "    crop_offset = 3\n",
    "    for area in areas:\n",
    "        # Cropping an image\n",
    "        x, y, w, h = area\n",
    "        if y <= crop_offset:\n",
    "            cropped_image = image[y:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "        else:\n",
    "            cropped_image = image[y-crop_offset:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "        mats.append(cropped_image)\n",
    "        # show(cropped_image, 'Crop')\n",
    "    return mats\n",
    "# cv2.imwrite(filename_4_saving, image_4_plot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the path to the 'scans' directory using the current file's location\n",
    "script_directory = os.getcwd()\n",
    "scans_directory = os.path.join(script_directory, '..', 'data/scans')\n",
    "output_directory = os.path.join(script_directory, '..', 'data/outputs')\n",
    "\n",
    "# Specify the path to your .tif file\n",
    "# file = 'scan0157'\n",
    "file = '4bl'\n",
    "tif_file_path = scans_directory + \"/\" + f\"{file}.tif\"\n",
    "filename_4_saving = output_directory + \"/\" + f\"{file}.png\"\n",
    "\n",
    "# Read the .tif file\n",
    "image = cv2.imread(tif_file_path, cv2.IMREAD_UNCHANGED)\n",
    "MIN_AREA = 2000\n",
    "MAX_AREA = 1000000\n",
    " \n",
    "scale_factor = {'x': 1, 'y': 1}\n",
    "# image = cv2.resize(image, None, fx=scale_factor['x'], fy=scale_factor['y'])\n",
    "grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def show(image, name='Result'):\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "if 'g' in file:\n",
    "    # GREEN\n",
    "    hsv_min = np.array((56, 66, 10), np.uint8)\n",
    "    hsv_max = np.array((100, 255, 188), np.uint8)\n",
    "elif 'bl' in file:\n",
    "    # black\n",
    "    hsv_min = np.array((0, 0, 17), np.uint8)\n",
    "    hsv_max = np.array((179, 115, 76), np.uint8)\n",
    "elif 'b' in file:\n",
    "    # BLUE\n",
    "    hsv_min = np.array((28, 160, 73), np.uint8)\n",
    "    hsv_max = np.array((139, 255, 255), np.uint8)\n",
    "elif 'r' in file:\n",
    "    # RED\n",
    "    hsv_min = np.array((0, 166, 27), np.uint8)\n",
    "    hsv_max = np.array((180, 255, 255), np.uint8)\n",
    "else:\n",
    "    # white\n",
    "    hsv_min = np.array((0, 0, 221), np.uint8) # 0, 0, 221\n",
    "    hsv_max = np.array((139, 11, 255), np.uint8) # 139, 11, 255"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(image, 'Original')\n",
    "# define the alpha and beta\n",
    "# alpha = 0.92 # Contrast control\n",
    "# beta = 10 # Brightness control\n",
    "#\n",
    "# # call convertScaleAbs function\n",
    "# adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV )\n",
    "thresh = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "binary_thresh = thresh / 255\n",
    "show(thresh, 'thresh')\n",
    "\n",
    "# Create a blank mask of the same size as the input image\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "# Create an empty mask\n",
    "inverted_thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "show(inverted_thresh, 'inverted_thresh')\n",
    "\n",
    "# Find contours in the mask\n",
    "mask_contours, _ = cv2.findContours(inverted_thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an output image (initially a copy of the original image)\n",
    "output_image = thresh.copy()\n",
    "img_copy = image.copy()\n",
    "crop_offset = 3\n",
    "cropped_images = []\n",
    "# Loop over the contours\n",
    "for contour in mask_contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    if 200000 < area:\n",
    "        inverted_thresh_copy = inverted_thresh.copy()\n",
    "        thresh_copy = thresh.copy()\n",
    "\n",
    "        # Detect the convex contour\n",
    "        hull = cv2.convexHull(contour)\n",
    "        img_hull = cv2.drawContours(img_copy, contours = [hull],\n",
    "                                contourIdx = 0,\n",
    "                                color = (255, 0, 0), thickness = 2)\n",
    "        # show(img_hull, 'img_hull')\n",
    "        # Convert hull points to the correct format for cv2.fillPoly\n",
    "        hull_points = np.array(hull, dtype=np.int32)\n",
    "\n",
    "        # Draw a filled polygon on the mask\n",
    "        cv2.fillPoly(inverted_thresh_copy, [hull_points], 255)\n",
    "        cv2.fillPoly(thresh_copy, [hull_points], 255)\n",
    "\n",
    "        # Apply the mask to the output to retain pixels outside the hull\n",
    "        final_mask = cv2.bitwise_and(thresh_copy, inverted_thresh_copy)\n",
    "\n",
    "        # Create a white image of the same size as the original image\n",
    "        white_image = np.ones_like(img_copy) * 255\n",
    "\n",
    "        # Apply the mask: where mask is 0, use white_image; where mask is 1, use the original image\n",
    "        masked_image = np.where(final_mask[:, :, np.newaxis] == 0, white_image, image)\n",
    "\n",
    "        # Cropping an image\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if y <= crop_offset and x <= crop_offset:\n",
    "            cropped_image = masked_image[y:(y+h+crop_offset), x:(x+w+crop_offset)]\n",
    "        elif y <= crop_offset:\n",
    "            cropped_image = masked_image[y:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "        elif x <= crop_offset:\n",
    "            cropped_image = masked_image[y-crop_offset:(y+h+crop_offset), x:(x+w+crop_offset)]\n",
    "        else:\n",
    "            cropped_image = masked_image[y-crop_offset:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "\n",
    "        cropped_images.append(cropped_image)\n",
    "        show(cropped_image, 'cropped_image')\n",
    "\n",
    "        # cv2.bitwise_and(thresh_copy, thresh_copy, mask=mask)\n",
    "        # show(masked_image, 'final_mask')\n",
    "\n",
    "# # Create a white image of the same size as the original image\n",
    "# white_image = np.ones_like(image) * 255\n",
    "#\n",
    "# # Apply the mask: where mask is 0, use white_image; where mask is 1, use the original image\n",
    "# masked_image_color = np.where(thresh[:, :, np.newaxis] == 255, white_image, image)\n",
    "# show(masked_image_color, 'masked_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# define the alpha and beta\n",
    "alpha = 0.95 # Contrast control\n",
    "beta = 20 # Brightness control\n",
    "\n",
    "# call convertScaleAbs function\n",
    "adjusted = cv2.convertScaleAbs(image, alpha=alpha)\n",
    "show(adjusted, 'adjusted')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "\n",
    "# Create a white image of the same size as the original image\n",
    "white_image = np.ones_like(image) * 255\n",
    "\n",
    "# Apply the mask: where mask is 0, use white_image; where mask is 1, use the original image\n",
    "masked_image_color = np.where(thresh[:, :, np.newaxis] == 255, white_image, image)\n",
    "show(masked_image_color, 'masked_image')\n",
    "\n",
    "dilate = preprocessing(masked_image_color)\n",
    "img, contours, areas = find_contours(masked_image_color, dilate)\n",
    "img_copy = masked_image_color.copy()\n",
    "crop_offset = 3\n",
    "cropped_images = []\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area > 100000:\n",
    "        # Detect the convex contour\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        img_hull = cv2.drawContours(img_copy, contours = [hull],\n",
    "                                    contourIdx = 0,\n",
    "                                    color = (255, 0, 0), thickness = 2)\n",
    "        # Created a new mask and used bitwise_and to select for contours:\n",
    "        mask = np.ones_like(img_copy[:, :, 0], dtype=np.uint8)\n",
    "        # mask = np.zeros_like(img_copy)\n",
    "        cv2.drawContours(mask, [hull], 0, (255, 255, 255), -1)\n",
    "        # show(img_hull, 'MASK')\n",
    "\n",
    "        # Create a white image of the same size as the original image\n",
    "        white_image = np.ones_like(img_copy) * 255\n",
    "\n",
    "        # Apply the mask: where mask is 0, use white_image; where mask is 1, use the original image\n",
    "        masked_image = np.where(mask[:, :, np.newaxis] == 1, white_image, masked_image_color)\n",
    "\n",
    "        # Cropping an image\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if y <= crop_offset:\n",
    "            cropped_image = masked_image[y:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "        else:\n",
    "            cropped_image = masked_image[y-crop_offset:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "\n",
    "        cropped_images.append(cropped_image)\n",
    "        show(cropped_image)\n",
    "# show(img_copy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dilate1 \u001B[38;5;241m=\u001B[39m preprocessing(\u001B[43mcropped_images\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m      2\u001B[0m img1, contours1, areas1 \u001B[38;5;241m=\u001B[39m find_contours(cropped_images[\u001B[38;5;241m0\u001B[39m], dilate1)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# show(img1)\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dilate1 = preprocessing(cropped_images[0])\n",
    "img1, contours1, areas1 = find_contours(cropped_images[0], dilate1)\n",
    "# show(img1)\n",
    "\n",
    "img1_copy = img1.copy()\n",
    "\n",
    "for cnt in contours1:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area > 1000:\n",
    "        # Detect the convex contour\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        img_hull = cv2.drawContours(img1_copy, contours = [hull],\n",
    "                                    contourIdx = 0,\n",
    "                                    color = (255, 0, 0), thickness = 2)\n",
    "        # Created a new mask and used bitwise_and to select for contours:\n",
    "        # mask = np.ones_like(img1_copy[:, :, 0], dtype=np.uint8)\n",
    "        # cv2.drawContours(mask, [hull], -1, 0, -1)\n",
    "        #\n",
    "        # # Create a white image of the same size as the original image\n",
    "        # white_image = np.ones_like(img1) * 255\n",
    "        #\n",
    "        # # Apply the mask: where mask is 0, use white_image; where mask is 1, use the original image\n",
    "        # masked_image = np.where(mask[:, :, np.newaxis] == 1, white_image, img1)\n",
    "        #\n",
    "        # # Cropping an image\n",
    "        # x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # cropped_image = masked_image[y-crop_offset:(y+h+crop_offset), x-crop_offset:(x+w+crop_offset)]\n",
    "        # cropped_images.append(cropped_image)\n",
    "        show(img_hull)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.contorArea(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'convexHull'\n> Overload resolution failed:\n>  - points is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'points'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# contours = max(contours, key = lambda x: cv2.contourArea(x))\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Created a new mask and used bitwise_and to select for contours:\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m hull \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvexHull\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontours\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(image)\n\u001B[1;32m      5\u001B[0m cv2\u001B[38;5;241m.\u001B[39mdrawContours(mask, [hull], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m255\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'convexHull'\n> Overload resolution failed:\n>  - points is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'points'\n"
     ]
    }
   ],
   "source": [
    "# contours = max(contours, key = lambda x: cv2.contourArea(x))\n",
    "# Created a new mask and used bitwise_and to select for contours:\n",
    "hull = cv2.convexHull(contours)\n",
    "mask = np.zeros_like(image)\n",
    "cv2.drawContours(mask, [hull], -1, (255, 255, 255), -1)\n",
    "masked_image = cv2.bitwise_and(image, mask)\n",
    "show(masked_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ret , thrash = cv2.threshold(grayImage, 226 , 255, cv2.CHAIN_APPROX_NONE)\n",
    "contours , hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "image_4_plot = image.copy()\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area>150000:\n",
    "        print(area)\n",
    "        approx = cv2.approxPolyDP(contour, 0.01* cv2.arcLength(contour, True), True)\n",
    "        cv2.drawContours(image_4_plot, [approx], 0, (255, 0, 0), 2)\n",
    "        x = approx.ravel()[0]\n",
    "        y = approx.ravel()[1] - 5\n",
    "\n",
    "        if len(approx) == 3:\n",
    "            cv2.putText(image_4_plot, \"Triangle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0) )\n",
    "        elif len(approx) == 4 :\n",
    "            x, y , w, h = cv2.boundingRect(approx)\n",
    "            aspectRatio = float(w)/h\n",
    "            print(aspectRatio)\n",
    "            if aspectRatio >= 0.95 and aspectRatio < 1.05:\n",
    "                cv2.putText(image_4_plot, \"square\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "            else:\n",
    "                cv2.putText(image_4_plot, \"rectangle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "        elif len(approx) == 5 :\n",
    "            cv2.putText(image_4_plot, \"pentagon\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "        elif len(approx) == 10 :\n",
    "            cv2.putText(image_4_plot, \"star\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "        else:\n",
    "            cv2.putText(image_4_plot, \"circle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "cv2.imshow('shapes', image_4_plot)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nothing(x):pass\n",
    "\n",
    "\n",
    "cv2.namedWindow('videoUI', cv2.WINDOW_NORMAL)\n",
    "cv2.createTrackbar('T','videoUI',0,255,nothing)\n",
    "\n",
    "while(True):\n",
    "    # vid_gray = cv2.cvtColor(grayImage, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.getTrackbarPos('T','videoUI')\n",
    "    ret,thresh = cv2.threshold(gray,thresh,255,0)  #to detect white objects\n",
    "    #to get outer boundery only\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_GRADIENT, kernel)\n",
    "    #to strength week pixels\n",
    "    thresh = cv2.dilate(thresh,kernel,iterations = 5)\n",
    "    # vid_bw = cv2.threshold(grayImage, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    cv2.imshow('videoUI',cv2.flip(thresh,1))\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
